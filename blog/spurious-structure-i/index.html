<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.101.0" />
<title>Spurious modular structure in functional brain networks | areshenkBlog</title>


<meta property="twitter:site" content="@apreshill">
<meta property="twitter:creator" content="@apreshill">







  
    
  
<meta name="description" content="">


<meta property="og:site_name" content="areshenkBlog">
<meta property="og:title" content="Spurious modular structure in functional brain networks | areshenkBlog">
<meta property="og:description" content="" />
<meta property="og:type" content="page" />
<meta property="og:url" content="https://areshenk.github.io/blog/spurious-structure-i/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="https://areshenk.github.io/blog/sidebar-listing.jpg" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="https://areshenk.github.io/blog/sidebar-listing.jpg" >
    
    
  <meta itemprop="name" content="Spurious modular structure in functional brain networks">
<meta itemprop="description" content="EDIT (Feb 26, 2019): So it turns out I’m not the first to notice this. Jaroslav Hlinka et al. identified this problem as early as 2012. They even attribute it to the same cause: the (partial) transitivity of the sample correlation.
The small-world properties of fMRI functional connectivity graphs obtained using standard methods have been shown to be largely reproduced or even exceeded by a matching randomly connected multivariate autoregressive process."><meta itemprop="datePublished" content="2018-12-10T00:00:00+00:00" />
<meta itemprop="dateModified" content="2018-12-10T00:00:00+00:00" />
<meta itemprop="wordCount" content="1619">
<meta itemprop="keywords" content="" />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/img/favicon.ico" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.f1b88c869e9feb00a1fe21e8f9979826ba90e026e18b274307b59fb8cfe5103c.css" integrity="sha256-8biMhp6f6wCh/iHo&#43;ZeYJrqQ4CbhiydDB7WfuM/lEDw=" media="screen">
  
  
  <script src="/panelset.min.dca42702d7daf6fd31dc352efd2bcf0e4ac8c05ccaa58d9293f6177462de5d5f.js" type="text/javascript"></script>
  
  
  <script src="/main.min.d8c0309a9ae249291c79de33e77e8dfa4fa659967e9198392fb7cff6c392ea63.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="https://areshenk.github.io/" title="Home">
      <img src="/img/blogophonic-mark-dark.png" class="dib db-l h2 w-auto" alt="areshenkBlog">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/" title="About">About</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/blog/" title="Blog">Blog</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/project/" title="Project Portfolio">Projects</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">Spurious modular structure in functional brain networks</h1>
        
        <p class="f6 measure lh-copy mv1">By Corson N. Areshenkoff</p>
        <p class="f7 db mv0 ttu">December 10, 2018</p>

      

      </header>
      <section class="post-body pt5 pb4">
        


<p><strong>EDIT (Feb 26, 2019):</strong> So it turns out I’m not the first to notice this. Jaroslav Hlinka et al. identified this problem as early as 2012. They even attribute it to the same cause: the (partial) transitivity of the sample correlation.</p>
<blockquote>
The small-world properties of fMRI functional connectivity graphs obtained using standard methods have been shown to be largely reproduced or even exceeded by a matching randomly connected multivariate autoregressive process. This result shows for the first time that the small-world properties of functional connectivity real-world graphs can be indeed attributed to the transitive properties of the correlation coefficient, as previously conjectured.
</blockquote>
<p>They go on to conclude</p>
<blockquote>
Our results suggest that most, if not all, of the observed effect in the brain data is attributable to the small-world bias of the correlation matrix
</blockquote>
<p>It’s certainly disappointing that no one in the network neuroscience community has felt the need to acknowledge this fact, even though several of them have published in this same journal.</p>
<p style="margin-left: .5in; text-indent: -.5in;">
Hlinka, J., Hartman, D., &amp; Paluš, M. (2012). Small-world topology of functional connectivity in randomly connected dynamical systems. Chaos: An Interdisciplinary Journal of Nonlinear Science, 22(3), 033107.
</p>
<p style="margin-left: .5in; text-indent: -.5in;">
Hlinka, J., Hartman, D., Jajcay, N., Tomeček, D., Tintěra, J., &amp; Paluš, M. (2017). Small-world bias of correlation networks: From brain to climate. Chaos: An Interdisciplinary Journal of Nonlinear Science, 27(3), 035812.
</p>
<hr />
<p><strong>Original post:</strong></p>
<p>Mehler and Kording (2018) just put out a very nice paper on the very flimsy theoretical foundations of network neuroscience, the general impossibility of inferring causal dynamics, or even connectivity itself, from standard approaches to brain connectivity analysis, and the inability to accurately recover the underlying network structure. Riffing on this idea, I want to point out one specific example where properties of networks constructed from neuroimaging data don’t necessarily reflect any real property of the underlying brain circuitry.</p>
<p>Graph theoretic approaches to the analysis of functional brain connectivity use recorded brain activity (most commonly, BOLD fMRI) during resting state or task to construct graphs representing (supposedly) functional connectivity between distinct brain regions. These graphs are often claimed to possess some kind of modular structure – roughly, a clustered organization in which nodes are densely connected within clusters, and relatively sparsely connected between them. This is usually considered to be a special or noteworthy feature of biological networks, as “random graphs” don’t generally display this kind of modularity. More importantly, the modularity observed in functional brain networks is usually assumed to reflect some underlying organization or structure within the brain – that is, the organization of the brain into distinct functional modules. It’s this second view that I take issue with. Below, I’ll show how the techniques used to estimate functional brain networks can easily <i>engineer</i> highly modular networks, even when all nodes in the network are completely independent. It follows that the mere appearance of modularity in empirical brain networks is not, in and of itself, evidence for any particular modular organization within the brain.</p>
<p>Suppose that we record mean BOLD signals from a set of brain regions during the performance of a cognitive task. We then apply a standard fMRI preprocessing pipeline, band-pass filter the data within a frequency range commonly associated with cognitive performance, compute the pairwise correlations between regions, and then threshold the correlation matrix to obtain a graph. We compute a few summary statistics for the graph and find that it has substantial structure compared to a null model – a random graph in which vertices are joined by an edge independently at random. Do we then have evidence that these brain regions are communicating with each other, or exhibit some kind of large scale network structure?</p>
<p>Here’s the tricky part: What we <i>meant</i> by our null model is a network in which there are no true relationships between brain regions. What we <i>actually specified</i> was a random graph. The problem is that the two are not the same – standard approaches to preprocessing fMRI data and constructing functional networks can <i>introduce</i> spurious structure into the graph, even when the underlying signals are independent.</p>
<p>Let’s simulate some data: We’ll generate 250 datasets consisting of <span class="math inline">\(N = 150\)</span> white noise signals of length <span class="math inline">\(T = 100\)</span>. FMRI data are typically low pass filtered, and functional connectivity analyses are usually carried out in frequency ranges roughly between .025 Hz and .15 Hz, so we’ll low-pass filter the data with a cutoff between .025 Hz and .175 Hz, in steps of .025. For each of these cutoffs, we’ll construct graphs by thresholding the matrices of pairwise correlations between signals.</p>
<p>What kind of structure can we expect to see, keeping in mind that our signals are pure, uncorrelated white noise? To start with, let’s get a sense of what the correlations actually look like. For each filter cutoff, I’ve plotted the distribution of the Pearson correlation coefficient below:</p>
<p><img src="img/fig1.png" width="100%" /></p>
<p>Notice the increased variance and, ultimately, clustering at the boundaries, at lower frequencies. This is completely intuitive: consider the limiting case, when the smoothing is so severe that the signals are essentially linear over their recorded length. In that case, any two either increase/decrease together (a perfect correlation); one increases while another decreases (perfect anti-correlation); or one or both of the signals are zero (zero correlation). So the correlation is effectively binarized in the limit.</p>
<p>As a digression, this has practical consequences for researchers who misuse significance tests. What is a “significant” correlation? Using a standard t-test, the test statistic for a correlation <span class="math inline">\(r\)</span> is
<span class="math display">\[ t = r \sqrt{\frac{n-2}{1-r^2}} \]</span>
which has a <span class="math inline">\(t_{n-2}\)</span> distribution under the null hypothesis of zero correlation under the assumption that the <span class="math inline">\(n\)</span> observations are independent and bivariate normal. But smoothing (or low-pass filtering in general) introduces autocorrelation, which makes larger correlations more common, which inflates the false positive rate of the test. See below for the error rate for a significance threshold of <span class="math inline">\(\alpha = .05\)</span>:</p>
<p><img src="img/fig2.png" width="100%" /></p>
<p>So for a filter cutoff of .175 Hz (in the ballpark of commonly used cutoffs in the fMRI literature), a t-test with a nominal type I error rate of .05 has an actual error rate of over .2 – over four times higher. See Lazic (2010) for other examples of scientists not understanding dependence.</p>
<p>This clustering towards the boundaries actually has interesting implications for the structure of thresholded correlation networks. Now, correlation is not transitive in general – if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are positively correlated, and <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span> are positively correlated, it is not necessarily the case that <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> are also positively correlated. But there’s a limit – because covariance is an inner-product, a little linear algebra gives us
<span class="math display">\[ r_{XZ} \geq r_{XY}r_{YZ} - \sqrt{1-r_{XY}^2}\sqrt{1-r_{YZ}^2}. \]</span>
If both <span class="math inline">\(r_{XY}\)</span> and <span class="math inline">\(r_{YZ}\)</span> are at least <span class="math inline">\(\theta\)</span>, then this implies <span class="math inline">\(r_{XZ} \geq 2\theta^2-1\)</span>. In other words, <i>sufficiently extreme</i> correlations exhibit transitivity. What does transitivity mean in the context of a graph? It means triangles. So two things happen here: The clustering of the correlation coefficient towards the boundaries at lower filter cutoffs increases the prevalence of triangles in the resulting correlation network, and the process of thresholding – removing <i>lower</i> correlations – selectively kills those edges <i>least</i> likely to be part of a triangle. We can see this through simulation: here are the mean number of triangles for the correlation networks constructed for each filter cutoff (thresholded at 30% edge density, as advocated by Zhang, et al., 2016).</p>
<p><img src="img/fig3.png" width="100%" /></p>
<p>At the most extreme cutoff, we have over twice as many triangles <i> for the same edge density</i>. What does this mean for the graph topology? It means clustering. We can take a look at a few measures: Louvain modularity, the clustering coefficient, Humphries’ (2008) measure of small worldness, and the number of clusters (as detected by Louvain clustering)</p>
<p><img src="img/fig4.png" width="100%" /></p>
<p><img src="img/fig5.png" width="100%" /></p>
<p><img src="img/fig6.png" width="100%" /></p>
<p><img src="img/fig7.png" width="100%" /></p>
<p>So we see that, at low frequencies, correlation networks constructed from uncorrelated white noise exhibit: A) substantial modularity; B) substantial clustering; C) “small-worldness”; and D) a relatively small number of clusters. In other words, they look exactly like functional brain networks.</p>
<p>Of course, “substantial modularity” (for example) is only substantial relative to a null model – commonly chosen to be something like an Erdos-Renyi random graph, in which pairs of vertices are joined independently at random, or a Newman–Girvan null model, which preserves the expected degree of each node Both of these null models are arguably scientifically uninteresting, as when edges represent correlations (or other measures which behave like inner-products; i.e. kernels), edges cannot be added or removed independently due to the correlation’s (partial) transitivity. This means that correlation graphs constructed from random noise are not <i>random graphs</i> in the Erdos-Renyi or Newman-Girvan sense – they have more structure. Tests against these null models don’t necessarily provide the information we want, which is whether an observed correlation network exhibits modularity beyond the substantial modularity already intrinsic to correlation networks constructed from autocorrelated time series,</p>
<p>Of course, none of this is to say that all reported functional connectivity analyses are spurious – many authors have successfully used functional connectivity estimates to do prediction, for example – but published claims that fMRI correlation networks exhibit “modular structure” are much less impressive when similar degrees of modularity can obtained from filtered white noise.</p>
<h3>
References
</h3>
<p style="margin-left: .5in; text-indent: -.5in;">
Humphries, M. D., &amp; Gurney, K. (2008). Network ‘small-world-ness’: a quantitative method for determining canonical network equivalence. PloS one, 3(4), e0002051.
</p>
<p style="margin-left: .5in; text-indent: -.5in;">
Lazic, S. E. (2010). The problem of pseudoreplication in neuroscientific studies: is it affecting your analysis?. BMC neuroscience, 11(1), 5.
</p>
<p style="margin-left: .5in; text-indent: -.5in;">
Mehler, D. M. A., &amp; Kording, K. P. (2018). The lure of causal statements: Rampant mis-inference of causality in estimated connectivity. arXiv preprint arXiv:1812.03363.
</p>
<p style="margin-left: .5in; text-indent: -.5in;">
Zhang, Z., Telesford, Q. K., Giusti, C., Lim, K. O., &amp; Bassett, D. S. (2016). Choosing wavelet methods, filters, and lengths for functional brain network construction. PloS one, 11(6), e0157243.
</p>

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">December 10, 2018</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">8 minute read, 1619 words</dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="https://areshenk.github.io/blog/spurious-structure-ii/">&larr; More spurious modular structure in functional brain networks</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="https://areshenk.github.io/blog/calibrating-surprise/">Calibrating surprise in high dimensions &rarr;</a>
  
</div>

      </footer>
    </article>
    
  </section>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2022 RStudio, Anywhere
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Apéro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0">
      <div class="social-icon-links" aria-hidden="true">
  
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://github.com/areshenk" title="github" target="_blank" rel="noopener">
      <i class="fab fa-github fa-lg fa-fw"></i>
    </a>
  
</div>

    </div>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
