<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.108.0">
<title>Calibrating surprise in high dimensions | areshenkBlog</title>


<meta property="twitter:site" content="@apreshill">
<meta property="twitter:creator" content="@apreshill">







  
    
  
<meta name="description" content="">


<meta property="og:site_name" content="areshenkBlog">
<meta property="og:title" content="Calibrating surprise in high dimensions | areshenkBlog">
<meta property="og:description" content="" />
<meta property="og:type" content="page" />
<meta property="og:url" content="https://areshenk.github.io/blog/calibrating-surprise/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="https://areshenk.github.io/blog/sidebar-listing.jpg" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="https://areshenk.github.io/blog/sidebar-listing.jpg" >
    
    
  <meta itemprop="name" content="Calibrating surprise in high dimensions">
<meta itemprop="description" content="Most reported results in mass-univariate studies – particularly, fMRI – are, implicitly, order statistics, in the sense that they are selected out of a superset of total comparisons based on some rank ordering of effect size. Most introductory statistics courses restrict themselves to univariate toy examples, and so it’s very difficult to develop any intuition about what constitutes a “surprising” result in this setting. A sure sign that a researcher’s surprisal is miscalibrated is an implicit comparison to an incorrect null – such as in the rule of thumb that a correlation of ."><meta itemprop="datePublished" content="2018-05-21T00:00:00+00:00" />
<meta itemprop="dateModified" content="2018-05-21T00:00:00+00:00" />
<meta itemprop="wordCount" content="920">
<meta itemprop="keywords" content="" />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/img/favicon.ico" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.977927cc9fbb8267905a51fc736bee04a98f0fee4d68d13a30997d8aeb6967de.css" integrity="sha256-l3knzJ&#43;7gmeQWlH8c2vuBKmPD&#43;5NaNE6MJl9iutpZ94=" media="screen">
  
  
  <script src="/panelset.min.ed1ac24b6e16f4e2481e3d1d098ae66f5bc77438aef619e6e266d8ac5b00dc72.js" type="text/javascript"></script>
  
  
  <script src="/main.min.e567f7e8ac7c79035da4f709e5d53dd1f0ab375425524ad1e9d79dd672a9678b.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="https://areshenk.github.io/" title="Home">
      <img src="/img/blogophonic-mark-dark.png" class="dib db-l h2 w-auto" alt="areshenkBlog">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/" title="About">About</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/research/" title="Research">Research</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/blog/" title="Blog">Blog</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/project/" title="Project Portfolio">Projects</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/areshenk_cv.pdf" title="CV">CV</a>
      
      
    </div>
  </nav>
</header>

<main class="page-main pa4" role="main">
  <section class="page-content mw8 center">
    <article class="post-content pa0 ph4-l">
      <header class="post-header">
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">Calibrating surprise in high dimensions</h1>
        
        <p class="f6 measure lh-copy mv1">By Corson N. Areshenkoff</p>
        <p class="f7 db mv0 ttu">May 21, 2018</p>

      

      </header>
      <section class="post-body pt5 pb4 f5">
        
<script src="https://areshenk.github.io/blog/calibrating-surprise/index_files/header-attrs/header-attrs.js"></script>


<p>Most reported results in mass-univariate studies – particularly, fMRI – are, implicitly, order statistics, in the sense that they are selected out of a superset of total comparisons based on some rank ordering of effect size. Most introductory statistics courses restrict themselves to univariate toy examples, and so it’s very difficult to develop any intuition about what constitutes a “surprising” result in this setting. A sure sign that a researcher’s surprisal is miscalibrated is an implicit comparison to an incorrect null – such as in the rule of thumb that a correlation of .5 is “large”.</p>
<p>In a typical mass-univariate setting, we observe a large number of effects – generally treated as if they are independent – and sift out the largest by significance testing, or some other threshold on effect size. The interpretation of the resulting “significant” effects is complicated by the fact that most intuition for what constitutes a “surprising” or “large” effect is developed in the univariate setting, and implicitly (or explicitly, in the case of significance testing) references a baseline of “no effect”, while the filtering over large numbers of effects actually implies a different null model.</p>
<p>Let’s be explicit. Consider a realistic setting in neuroimaging, where we measure pairwise structural connectivity (say, by DTI tractography) between a large number of brain regions. We then want to identify which (if any) connections are correlated with performance on some cognitive task. Searching over all pairs of regions, we find a significant connection which has a correlation of <span class="math inline">\(r = .5\)</span> with task performance, which is commonly called a “strong” correlation in the social sciences. Is this correlation surprising? Is it actually evidence of anything?</p>
<p>A typical cortical atlas might easily contain upwards of 100 distinct regions, giving upwards of <span class="math inline">\({100\choose 2} = 4950\)</span> total pairwise connections. What is the strongest correlation we can expect to find in these data? We can actually compute this explicitly given a few assumptions – specifically, that task performance and connection strength are jointly normal for each connection, and that the set of connections are independent (which is slightly more realistic for structural than for functional connectivity).</p>
<p>Suppose that that the true correlation is zero. For a pair of jointly normal, uncorrelated random variables, the sample correlation has density
<span class="math display">\[
        f(r) = \frac{1}{B(\frac{1}{2}, \frac{1}{2}(n-2))} (1-r^2)^{\frac{1}{2}(n-4)}
    \]</span></p>
<pre class="r"><code>dcor &lt;- function(r, n) {
    (1-r^2)^((n-4)/2) / beta(1/2, (n-2)/2)
}</code></pre>
<p>where <span class="math inline">\(n\)</span> is the sample size and <span class="math inline">\(B\)</span> is the beta function. The cumulative distribution function is then
<span class="math display">\[\begin{align*}
        F(r) &amp;= \frac{1}{B(\frac{1}{2}, \frac{1}{2}(n-2))} 
           \int_{-1}^r (1-s^2)^{\frac{1}{2}(n-4)} ds \\
             &amp;= \frac{1}{B(\frac{1}{2}, \frac{1}{2}(n-2))} 
                \left ( s _1F_2(\frac{1}{2}, -\frac{1}{2}(n-4);\frac{3}{2},r^2)\right ) 
                \Bigg |_{-1}^r
    \end{align*}\]</span></p>
<pre class="r"><code>library(hypergeo)
pcor &lt;- function(r, n) {
  const &lt;- 1/beta(1/2, (n-2)/2)
  upper &lt;- Re(r*hypergeo(1/2, -(n-4)/2, 3/2, r^2))
  lower &lt;- Re(-hypergeo(1/2, -(n-4)/2, 3/2, (-1)^2))
  return(const * (upper - lower))
}</code></pre>
<p>where <span class="math inline">\(_1F_2\)</span> is the hypergeometric function (note the the hypergeometric function is difficult to evaluate, and hypergeo in particular has difficulty with large sample sizes)</p>
<p>It’s easy to work out the distribution for the maximum order statistics. Given <span class="math inline">\(k\)</span> independent correlations, the CDF of the maximum is
<span class="math display">\[
  F_\text{max}(r) = F^k(r)
\]</span></p>
<pre class="r"><code>pmaxcor &lt;- function(r, n, k) {
  pcor(r, n)^k
}</code></pre>
<p>and the density is
<span class="math display">\[
  f_\text{max}(r) = kF^{k-1}(r)f(r)
\]</span></p>
<pre class="r"><code>dmaxcor &lt;- function(r, n, k) {
  k * pcor(r, n)^(k-1) * dcor(r, n)
}</code></pre>
<p>According to Turner et al. (2018), the median sample size of an fMRI study published in 2015 was about 28, which we’ll round to 30 for demonstration. For these study parameters</p>
<pre class="r"><code>n &lt;- 30
k &lt;- choose(100,2)</code></pre>
<p>the distribution of the maximum observed correlation is</p>
<pre class="r"><code>r &lt;- seq(-1, 1, .001)
plot(r, dmaxcor(r, n, k), type = &#39;l&#39;, 
     lwd = 2, cex.lab = 1.4, yaxt = &#39;n&#39;,
     xlab = &#39;Correlation&#39;, ylab = &#39;&#39;)
abline(v = 0, lty = 2)</code></pre>
<p><img src="img/unnamed-chunk-6-1.png" width="672" /></p>
<p>So we will essentially always observe a “strong” correlation (<span class="math inline">\(r \geq .5\)</span>) in this setting. In fact, this happens with probability</p>
<pre class="r"><code>1 - pmaxcor(.5, n, k)</code></pre>
<pre><code>## [1] 0.9999947</code></pre>
<p>when there are no true correlations anywhere. So a “strong” correlation is not only not surprising, it is completely consistent with the idea that there are no effects. Worse, even if there <i>are</i> strong effects, they are intermingled with the effects that can be expected from pure noise.</p>
<p>How large does our sample need to be resolve a large correlation from pure noise? Let’s accept a false positive rate of <span class="math inline">\(\alpha = .05\)</span> for a two-tailed probability.</p>
<pre class="r"><code>n     &lt;- seq(10,80,1)
alpha &lt;- .05
p     &lt;- 1 - pmaxcor(.5, n, k)
plot(n, p, xlab = &#39;Sample Size&#39;,
     ylab = &#39;False positive rate&#39;,
     type = &#39;l&#39;, lwd = 2, cex.lab = 1.25)
abline(h = alpha/2, col = &#39;red&#39;)</code></pre>
<p><img src="img/unnamed-chunk-8-1.png" width="672" /></p>
<p>So the minimum sample size needed to resolve even a large correlation from noise is</p>
<pre class="r"><code>n[which.max(p &lt;= alpha/2)]</code></pre>
<pre><code>## [1] 71</code></pre>
<p>which is more than twice the median sample size reported in the literature, and is not economically feasible for most labs, given the huge expense involved in running an imaging study. Taking the position that large true correlations between imaging data and behavior rarely, if ever, exist – the alternative being that a substantial proportion of the variance in noisy behavioral measurements can be explained by crude, noisy, and indirect summaries of brain structure or function, which seems implausible – this would suggest that almost all mass-univariate, correlation based imaging studies are dead out of the gate, excluding perhaps large, multi-lab collaborations.</p>
<div id="references" class="section level2">
<h2>References</h2>
<p style="margin-left: .5in; text-indent: -.5in;">
Turner, B. O., Paul, E. J., Miller, M. B., &amp; Barbey, A. K. (2018). Small sample sizes reduce the replicability of task-based fMRI studies. Communications biology, 1(1), 62.
</p>
</div>

        
        <details closed class="f6 fw7 input-reset">
  <dl class="f6 lh-copy">
    <dt class="fw7">Posted on:</dt>
    <dd class="fw5 ml0">May 21, 2018</dd>
  </dl>
  <dl class="f6 lh-copy">
    <dt class="fw7">Length:</dt>
    <dd class="fw5 ml0">5 minute read, 920 words</dd>
  </dl>
  
  
  
  <dl class="f6 lh-copy">
    <dt class="fw7">See Also:</dt>
    
  </dl>
</details>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="https://areshenk.github.io/blog/in-a-room-sit-three-textbooks/">&larr; In a room sit three textbooks...</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="https://areshenk.github.io/blog/cargo-cult-statistics/">Cargo cult statistics &rarr;</a>
  
</div>

      </footer>
    </article>
    
  </section>
</main>
<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2023 RStudio, Anywhere
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Apéro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0">
      <div class="social-icon-links" aria-hidden="true">
  
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://github.com/areshenk" title="github" target="_blank" rel="noopener">
      <i class="fab fa-github fa-lg fa-fw"></i>
    </a>
  
</div>

    </div>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
