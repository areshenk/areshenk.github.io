<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>areshenkBlog</title>
    <link>/blog/</link>
    <description>Recent content on areshenkBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 26 May 2019 00:00:00 +0000</lastBuildDate><atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spurious dynamics in functional brain networks</title>
      <link>/blog/spurious-structure-iii/</link>
      <pubDate>Sun, 26 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/spurious-structure-iii/</guid>
      <description>Network neuroscience (NN) as a field lacks statistical and theoretical justification for almost any of it’s techniques. The discipline consists largely of ad hoc measures whose statistical properties are very poorly understood and whose relationships to brain function (if they exist at all) have not been clearly established. Much of this stems from a lack of domain knowledge – network neuroscience is a very young field – but a part of it comes from a lack of methodological rigour in general.</description>
    </item>
    
    <item>
      <title>More spurious modular structure in functional brain networks</title>
      <link>/blog/spurious-structure-ii/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/spurious-structure-ii/</guid>
      <description>Even in the absence of any true underlying network structure, functional brain networks can easily show complex, modular structure, possibly due to a combination of the transitive-ish properties of most functional connectivity measures, and the standard approaches to fMRI preprocessing (esp. low pass filtering)
Assessment of dynamic functional connectivity usually involves estimating functional connectivity within a temporal sliding window, which requires the arbitrary selection of a window size. As with low-pass filtering, a small window length reduces the precision of the functional connectivity estimate by reducing the effective sample size, which should similarly result in greater modular structure.</description>
    </item>
    
    <item>
      <title>Spurious modular structure in functional brain networks</title>
      <link>/blog/spurious-structure-i/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/spurious-structure-i/</guid>
      <description>EDIT (Feb 26, 2019): So it turns out I’m not the first to notice this. Jaroslav Hlinka et al. identified this problem as early as 2012. They even attribute it to the same cause: the (partial) transitivity of the sample correlation.
The small-world properties of fMRI functional connectivity graphs obtained using standard methods have been shown to be largely reproduced or even exceeded by a matching randomly connected multivariate autoregressive process.</description>
    </item>
    
    <item>
      <title>Calibrating surprise in high dimensions</title>
      <link>/blog/calibrating-surprise/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/calibrating-surprise/</guid>
      <description>Most reported results in mass-univariate studies – particularly, fMRI – are, implicitly, order statistics, in the sense that they are selected out of a superset of total comparisons based on some rank ordering of effect size. Most introductory statistics courses restrict themselves to univariate toy examples, and so it’s very difficult to develop any intuition about what constitutes a “surprising” result in this setting. A sure sign that a researcher’s surprisal is miscalibrated is an implicit comparison to an incorrect null – such as in the rule of thumb that a correlation of .</description>
    </item>
    
    <item>
      <title>Cargo cult statistics</title>
      <link>/blog/cargo-cult-statistics/</link>
      <pubDate>Sun, 18 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/cargo-cult-statistics/</guid>
      <description>The failure of scientists, and particularly students in the sciences, to properly understand the most commonly used statistical concepts in their field has been extensively documented (see e.g. Sotos et al., 2007). Many of the specific misunderstandings are well known at this point to anyone with an interest in methodology – for example, Haller, et al. (2002) questioned students and faculty at several Universities and found that the overwhelming majority could not correctly define a p-value, a crisis that has launched a thousand publications.</description>
    </item>
    
  </channel>
</rss>
